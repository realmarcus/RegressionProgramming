print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
theta
X
X(1,:)
X(1,)
X
seq1 <- seq(1:6)
seq1
X[1,]
X[2,]
X[5,]
X
# SETUP
Sys.setlocale("LC_ALL", "C")
# Part 1: Basic Function
print ("Running warmUpExercise")
# 5x5 Identity Matrix
A = diag(3)
print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
# Some gradient descent settings
iterations = 1500
alpha = 0.01
J = 0
for (i in 1:m) {
Hi = theta %*% X[i,]
}
#J = J/(2*m);
Hi
theta
X[1,]
theta %*% X[1,]
# SETUP
Sys.setlocale("LC_ALL", "C")
# Part 1: Basic Function
print ("Running warmUpExercise")
# 5x5 Identity Matrix
A = diag(3)
print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
# Some gradient descent settings
iterations = 1500
alpha = 0.01
J = 0
for (i in 1:m) {
Hi = theta %*% X[i,]
Temp =( Hi-y[i])^2;
J = J+ Temp;
}
#J = J/(2*m);
# SETUP
Sys.setlocale("LC_ALL", "C")
# Part 1: Basic Function
print ("Running warmUpExercise")
# 5x5 Identity Matrix
A = diag(3)
print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
# Some gradient descent settings
iterations = 1500
alpha = 0.01
J = 0
for (i in 1:m) {
Hi = theta %*% X[i,]
Temp =( Hi-y[i])^2;
J = J+ Temp;
}
J = J/(2*m)
J
Hi
Temp
i
[0,0]
[0;0]
# SETUP
Sys.setlocale("LC_ALL", "C")
# Part 1: Basic Function
print ("Running warmUpExercise")
# 5x5 Identity Matrix
A = diag(3)
print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
# Some gradient descent settings
iterations = 1500
alpha = 0.01
J = 0
for (i in 1:m) {
Hi = theta %*% X[i,]
Temp =( Hi-y[i])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history = rep(0,iterations)
for (iter in 1:iterations) {
Temp = rep(0,2);
for (i in 1:m) {
for (j in 1:2) {
Hix = theta %*% X[i,]
Temp[j] = Temp[j]+(Hix - y[i])*X[i,j]
}
}
}
theta = theta-alpha %*% Temp/m
theta
Temp
X
J_history
# SETUP
Sys.setlocale("LC_ALL", "C")
# Part 1: Basic Function
print ("Running warmUpExercise")
# 5x5 Identity Matrix
A = diag(3)
print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
# Some gradient descent settings
iterations = 1500
alpha = 0.01
J = 0
for (i in 1:m) {
Hi = theta %*% X[i,]
Temp =( Hi-y[i])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history = rep(0,iterations)
for (iter in 1:iterations) {
Temp = rep(0,2);
for (i in 1:m) {
for (j in 1:2) {
Hix = theta %*% X[i,]
Temp[j] = Temp[j]+(Hix - y[i])*X[i,j]
}
}
theta = theta-alpha %*% Temp/m
J_history(iter) = computeCost(X, y, theta);
}
# SETUP
Sys.setlocale("LC_ALL", "C")
# Part 1: Basic Function
print ("Running warmUpExercise")
# 5x5 Identity Matrix
A = diag(3)
print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
# Some gradient descent settings
iterations = 1500
alpha = 0.01
J = 0
for (i in 1:m) {
Hi = theta %*% X[i,]
Temp =( Hi-y[i])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history = rep(0,iterations)
for (iter in 1:iterations) {
Temp = rep(0,2);
for (i in 1:m) {
for (j in 1:2) {
Hix = theta %*% X[i,]
Temp[j] = Temp[j]+(Hix - y[i])*X[i,j]
}
}
theta = theta-alpha %*% Temp/m
for (k in 1:m) {
Hi = theta %*% X[k,]
Temp =( Hi-y[k])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history(iter) = J;
}
# SETUP
Sys.setlocale("LC_ALL", "C")
# Part 1: Basic Function
print ("Running warmUpExercise")
# 5x5 Identity Matrix
A = diag(3)
print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
# Some gradient descent settings
iterations = 1500
alpha = 0.01
J = 0
for (i in 1:m) {
Hi = theta %*% X[i,]
Temp =( Hi-y[i])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history = rep(0,iterations)
for (iter in 1:iterations) {
Temp = rep(0,2);
for (i in 1:m) {
for (j in 1:2) {
Hix = theta %*% X[i,]
Temp[j] = Temp[j]+(Hix - y[i])*X[i,j]
}
}
theta = theta-alpha %*% Temp/m
for (k in 1:m) {
Hi = theta %*% X[k,]
Temp =( Hi-y[k])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history[iter] = J;
}
theta
J_history
plot(J_history)
# SETUP
Sys.setlocale("LC_ALL", "C")
# Part 1: Basic Function
print ("Running warmUpExercise")
# 5x5 Identity Matrix
A = diag(3)
print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
# Some gradient descent settings
iterations = 1500
alpha = 0.01
J = 0
for (i in 1:m) {
Hi = theta %*% X[i,]
Temp =( Hi-y[i])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history = rep(0,iterations)
for (iter in 1:iterations) {
Temp = rep(0,2);
for (i in 1:m) {
for (j in 1:2) {
Hix = theta %*% X[i,]
Temp[j] = Temp[j]+(Hix - y[i])*X[i,j]
}
}
theta = theta-alpha %*% Temp/m
for (k in 1:m) {
Hi = theta %*% X[k,]
Temp =( Hi-y[k])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history[iter] = J;
}
plot(X[,2], X %*% theta)
pwd
pwd()
getwd()
# SETUP
Sys.setlocale("LC_ALL", "C")
# Part 1: Basic Function
print ("Running warmUpExercise")
# 5x5 Identity Matrix
A = diag(3)
print(A)
# Part 2: Plotting
print("Plotting Data ...\n")
# SET FOLDER
setwd("C:\Users\Diallo\Documents\MachineLearningStanford\R")
# READ INPUT FILE
df = read.csv("MachineLearningStanford/R/ex1data1.csv")
# rename col names
colnames(df)<- c("X","y")
x = df$X
y = df$y
#number of training examples
m = length(y)
# plot data
plot(x,y)
# Part 3: Gradient descent
# X = [ones(m, 1), data(:,1)]; % Add a column of ones to x
X = cbind(1,x)
# initialize fitting parameters
theta = rep(0,2)
# Some gradient descent settings
iterations = 1500
alpha = 0.01
J = 0
for (i in 1:m) {
Hi = theta %*% X[i,]
Temp =( Hi-y[i])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history = rep(0,iterations)
for (iter in 1:iterations) {
Temp = rep(0,2);
for (i in 1:m) {
for (j in 1:2) {
Hix = theta %*% X[i,]
Temp[j] = Temp[j]+(Hix - y[i])*X[i,j]
}
}
theta = theta-alpha %*% Temp/m
for (k in 1:m) {
Hi = theta %*% X[k,]
Temp =( Hi-y[k])^2;
J = J+ Temp;
}
J = J/(2*m)
J_history[iter] = J;
}
plot(X[,2], X %*% theta)
PI
pi
r=0.9
r^3
4*pi*r^3/3
150*4*pi*r^3/3
8.6^2
20*8.6^2
3.6/12
getwd()
setwd("GitHub/RegressionProgramming/Detective/src/")
#libraries
library("dplyr")
library("ggplot2")
# import data
data <- read.csv("../data/mvtWeek1.csv")
# create data frame
df <- tbl_df(data)
# How many rows of data (observations) are in this dataset?
str(df)
# 191641 obs. of  11 variables
max(df.ID)
max(df$ID)
min(df$Beat)
summary(df)
source("assignment1Crime.R")
#libraries
library("dplyr")
library("ggplot2")
# import data
data <- read.csv("../data/mvtWeek1.csv")
# create data frame
df <- tbl_df(data)
# How many rows of data (observations) are in this dataset?
str(df)
# 191641 obs. of  11 variables
# Using the "max" function, what is the maximum value of the variable "ID"?
max(df$ID)
# What is the minimum value of the variable "Beat"?
min(df$Beat)
# How many observations have a LocationDescription value of ALLEY?
summary(df)
